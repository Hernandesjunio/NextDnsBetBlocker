# Table Storage Operational Guide ðŸ“Š

Um guia prÃ¡tico para operadores monitorarem e otimizarem o consumo de quota do Table Storage durante importaÃ§Ãµes de 4.8M+ domÃ­nios.

## Quick Reference

### Azure Table Storage Limits (por partition key)
```
Throughput:     20,000 RU/s (eventual consistency)
Entity size:    1 MB mÃ¡ximo
Batch size:     100 entities mÃ¡ximo
Request rate:   ~20k requests/s per partition
Max storage:    500 TB per account
```

### NextDnsBetBlocker Import Profile
```
Dataset:        5M+ domÃ­nios (Tranco 4.8M + Hagezi listas)
Batch size:     100 items
Partitions:     32 (hash-based distribution)
Target rate:    18-20k ops/s (mÃ¡ximo seguro)
Expected time:  ~4-5 minutos
Storage:        ~890 MB (1x import)
Cost:           ~$0.50 (transaction cost)
```

---

## Pre-Import Checklist

### 1. Verificar Quotas DisponÃ­veis
```kusto
// Query Application Insights
customMetrics
| where name == "ImportMetrics.StorageConsumed"
| summarize latest_mb=max(value) by bin(timestamp, 1h)
| tail 1
```

**AÃ§Ã£o**: Se > 400GB acumulado:
- Executar archival job (delete dados > 90 dias)
- Ou provisionar novo storage account

### 2. Verificar Status do Storage Account
```bash
az storage account show \
  --name <storage_account> \
  --resource-group <rg> \
  --query "properties.{created:creationTime, primaryLocation, statusOfPrimary}"
```

**AÃ§Ã£o**: Se status = "unavailable", aguardar ou failover

### 3. Limpar Cache Local (se necessÃ¡rio)
```bash
# Remover checkpoint de falha anterior (forÃ§ar re-import)
az storage table row delete \
  --account-name <storage> \
  --table-name Checkpoints \
  --partition-key ImportStatus \
  --row-key Tranco_TopDomains
```

---

## Durante o Import

### Monitoramento em Tempo Real

**Terminal 1: Taxa de processamento**
```kusto
customMetrics
| where name == "ImportMetrics.ItemsProcessed"
| summarize count=sum(value) by bin(timestamp, 10s)
| extend ops_per_sec = count / 10
| order by timestamp desc
```

**Terminal 2: Erros e throttles**
```kusto
customMetrics
| where name == "ImportMetrics.Error429Count"
| summarize errors=sum(value) by bin(timestamp, 1m)
| where errors > 0
```

**Terminal 3: DistribuiÃ§Ã£o por partiÃ§Ã£o**
```kusto
customMetrics
| where name == "ImportMetrics.PartitionItemCount"
| summarize items=sum(value) by tostring(customDimensions.PartitionKey)
| extend variance_pct = stdev(value) * 100 / avg(value)
```

### Alertas Red Flags

| MÃ©trica | Normal | AtenÃ§Ã£o | CrÃ­tico |
|---------|--------|---------|---------|
| **Ops/s** | 18-20k | 15-18k | < 10k |
| **Error 429/min** | 0 | 1-5 | > 10 |
| **Partition variance** | < 5% | 5-15% | > 20% |
| **Latency P99** | < 100ms | 100-500ms | > 1000ms |

**AÃ§Ãµes recomendadas:**

```
Se Error 429/min > 5:
  â”œâ”€ Aumentar `MaxRetries` (appsettings: 3 â†’ 5)
  â”œâ”€ Reduzir `MaxGlobalOperationsPerSecond` (20k â†’ 15k)
  â””â”€ Monitor prÃ³ximo ciclo

Se Ops/s < 10k:
  â”œâ”€ Verificar: network latency (ping storage account)
  â”œâ”€ Verificar: CPU/Memory do container
  â””â”€ Se persistir: rollback a partition count (32 â†’ 16)

Se Partition variance > 20%:
  â”œâ”€ Hash function pode estar ruim
  â”œâ”€ Fazer dump de um partition (10 items)
  â””â”€ Verificar: distribuiÃ§Ã£o de domÃ­nios
```

---

## Post-Import Validation

### Verificar Completude
```sql
-- SQL Query (apÃ³s import via Data Explorer)
SELECT 
  PartitionKey,
  COUNT(*) as ItemCount
FROM DomainListsTable
WHERE ImportedDate = CAST(GETDATE() AS DATE)
GROUP BY PartitionKey
ORDER BY ItemCount DESC
```

**Esperado**: 32 partiÃ§Ãµes, ~156k items cada, variance < 5%

### Verificar Integridade
```kusto
// Application Insights
customMetrics
| where name == "ImportMetrics.ValidationErrors"
| summarize errors=sum(value) by tostring(customDimensions.ErrorType)

// Alertar se > 0 duplicates apÃ³s validation
```

**AÃ§Ã£o**: Se erros > 0.1%:
- Revisar logs do GenericListImporter
- Verificar: source list integrity
- Rerun import

### Atualizar Checkpoint
```bash
# Via Azure Portal ou CLI
az storage table row merge \
  --account-name <storage> \
  --table-name Checkpoints \
  --partition-key ImportStatus \
  --row-key Tranco_TopDomains \
  --entity timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ) status=completed items=4998500
```

---

## Troubleshooting Comum

### Problema: 429 Too Many Requests

**Causa**: Exceeding 20k RU/s per partition

**DiagnÃ³stico**:
```kusto
customMetrics
| where name == "ImportMetrics.Error429Count"
| summarize errors=sum(value), ops=sum(value)*20
| extend inferred_ops_per_sec = ops / 300  // 5 min window
```

**SoluÃ§Ã£o**:
1. **Imediato**: Aumentar retry delay (exponential backoff)
2. **MÃ©dio prazo**: Reduzir parallelism (InitialDegreeOfParallelism: 25 â†’ 20)
3. **Longo prazo**: Premium Table Storage (10k RU/s provisioned)

### Problema: Timeout no Import

**Causa**: Network latency ou Container lento

**DiagnÃ³stico**:
```bash
# Testar latÃªncia de rede
ping blob.core.windows.net  # deve ser < 50ms
```

**SoluÃ§Ã£o**:
1. Aumentar timeout (appsettings: 30s â†’ 60s)
2. Reduzir batch size (100 â†’ 50)
3. Aumentar container memory (1 GB â†’ 2 GB)

### Problema: Partition Hot-Spot

**Causa**: Hash distribution ruim (ex: muitos domÃ­nios com mesmo prefixo)

**DiagnÃ³stico**:
```kusto
customMetrics
| where name == "ImportMetrics.PartitionItemCount"
| summarize items=sum(value) by PartitionKey
| extend variance = stdev(items) * 100 / avg(items)
| where variance > 20
```

**SoluÃ§Ã£o**:
1. Aumentar partition count (32 â†’ 64)
2. Usar hash diffÃ©rente (MD5 â†’ SHA256)
3. Pre-processor: shuffle items antes de partition

---

## Cost Monitoring

### Consumo Esperado (por import)

```
Storage cost:      ~$0.02  (890 MB a $0.018/GB)
Transaction cost:  ~$0.50  (50M ops a $0.01 per 10k ops)
Total per day:     ~$0.52
Monthly:           ~$15.60
Yearly:            ~$187.20
```

### Como Reduzir Custo

| TÃ©cnica | Economia | Tradeoff |
|---------|----------|----------|
| **Batch size: 100 â†’ 1000** | ~10x | Latency +100%, memory +10x |
| **Partition count: 32 â†’ 16** | ~2x (contention) | Risk de hot-spots |
| **Retention: 90d â†’ 30d** | ~3x | Menos histÃ³rico |
| **Delete archival daily** | ~1x | Operational complexity |

**Recomendado**: Kombiniert:
- Batch size = 100 (manter seguranÃ§a)
- 30-day retention (vs 90-day)
- Daily delete de dados antigos

---

## Optimization Playbook

### Fase 1: Baseline (Primeira execuÃ§Ã£o)
```
Objetivo: Entender caracterÃ­sticas reais
â”œâ”€ Execute com config padrÃ£o
â”œâ”€ Registre: throughput, errors, latency, cost
â””â”€ Documente: variaÃ§Ãµes vs expectativa
```

### Fase 2: Tune (Iterativo)
```
Se Ops/s < 15k:
  â”œâ”€ Aumentar InitialDegreeOfParallelism (20 â†’ 30)
  â”œâ”€ Aumentar MaxGlobalOperationsPerSecond (20k â†’ 25k)
  â””â”€ Rerun

Se Error 429 > 5/min:
  â”œâ”€ Reduzir MaxGlobalOperationsPerSecond (20k â†’ 15k)
  â”œâ”€ Aumentar MaxRetries (3 â†’ 5)
  â””â”€ Rerun
```

### Fase 3: Production (EstÃ¡vel)
```
Objetivo: OperaÃ§Ã£o confiÃ¡vel com alertas
â”œâ”€ Lock configuraÃ§Ã£o apÃ³s 3 successful runs
â”œâ”€ Setup alertas (429 errors, variance, latency)
â”œâ”€ Schedule: Daily @ 02:00 UTC
â””â”€ AutomÃ¡tico + manual oversight
```

---

## SLA & Health Metrics

### Target Metrics
```
Throughput:  18-20k ops/s
Latency:     < 100ms (p99)
Success:     > 99.9% (< 5k errors em 5M)
429 errors:  < 10/min (ideal: 0)
Variance:    < 10% (partitions balanceados)
Cost:        < $1/dia (target: ~$0.50)
```

### Dashboarding (Application Insights)

```json
{
  "name": "Import Monitoring",
  "tiles": [
    {
      "title": "Ops/sec",
      "metric": "ImportMetrics.ItemsProcessed",
      "aggregation": "sum",
      "timespan": "10s",
      "threshold": [15000, 20000]
    },
    {
      "title": "Error 429",
      "metric": "ImportMetrics.Error429Count",
      "aggregation": "sum",
      "timespan": "1m",
      "threshold": [0, 10]
    },
    {
      "title": "Partition Variance",
      "metric": "ImportMetrics.PartitionItemCount",
      "aggregation": "stdev",
      "threshold": ["< 5%", "> 20%"]
    }
  ]
}
```

---

## Contato & Escalation

**Observado comportamento anÃ´malo?**

1. **Coletar logs**: Export Application Insights logs (Ãºltimas 2 horas)
2. **Documentar**: 
   - HorÃ¡rio do evento
   - MÃ©trica afetada
   - Screenshot do dashboard
3. **Verificar**: Consultar Azure status page (status.azure.com)
4. **Reportar**: Abrir issue no GitHub com logs + diagnosis

---

**Ãšltima atualizaÃ§Ã£o**: 2024-01-15  
**VersÃ£o**: 1.0 (para 4.8M Tranco + Hagezi)
